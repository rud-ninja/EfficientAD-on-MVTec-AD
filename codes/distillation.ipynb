{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":998277,"sourceType":"datasetVersion","datasetId":547506}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Get data","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader, Subset\nimport torchvision.models as models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-29T09:59:57.521226Z","iopub.execute_input":"2024-04-29T09:59:57.522275Z","iopub.status.idle":"2024-04-29T10:00:02.728480Z","shell.execute_reply.started":"2024-04-29T09:59:57.522228Z","shell.execute_reply":"2024-04-29T10:00:02.727603Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n\n# grayscale_transform = transforms.RandomGrayscale(0.1)\n\nfext_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\npdn_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\ntrain_path = '/kaggle/input/imagenetmini-1000/imagenet-mini/train'\n\nfext_dataset = ImageFolder(root=train_path, transform=fext_transform)\npdn_dataset = ImageFolder(root=train_path, transform=pdn_transform)\n\ndataloader = DataLoader(fext_dataset, batch_size=50, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:00:05.510050Z","iopub.execute_input":"2024-04-29T10:00:05.511130Z","iopub.status.idle":"2024-04-29T10:00:16.986783Z","shell.execute_reply.started":"2024-04-29T10:00:05.511095Z","shell.execute_reply":"2024-04-29T10:00:16.985966Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Feature extractor (pretrained wide resnet 101","metadata":{}},{"cell_type":"code","source":"class FeatureExtractor(nn.Module):\n    \n    def __init__(self):\n        super().__init__()\n        \n        backbone = models.wide_resnet101_2(weights='DEFAULT')\n        \n        \n        self.initial = nn.Sequential(*list(backbone.children())[:5])\n        self.layr2 = backbone.layer2\n        self.layr3 = backbone.layer3\n        \n        self.unfold = nn.Unfold(kernel_size=3, stride=1, padding=1, dilation=1)\n        \n        \n    def forward(self, x):\n        \n        x = self.initial(x)      \n        x1 = self.layr2(x)\n        x2 = self.layr3(x1)\n        \n        x2_upsampled = F.interpolate(x2, size=(64, 64), mode='bilinear', align_corners=False)\n        \n        \n        concatenated_tensor = torch.cat((x1, x2_upsampled), dim=1)\n        \n        desired_channels = 384\n        aggregated_tensor = F.interpolate(concatenated_tensor.unsqueeze(0), size=(desired_channels, 64, 64), mode='trilinear').squeeze(0)\n        \n        \n        return aggregated_tensor\n    \n    \nfext = FeatureExtractor()\n\nfor name, param in fext.named_parameters():\n    param.requires_grad = False\n\nif torch.cuda.device_count() > 1:\n    fext = nn.DataParallel(fext)\n    \nfext = fext.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:00:23.555268Z","iopub.execute_input":"2024-04-29T10:00:23.555638Z","iopub.status.idle":"2024-04-29T10:00:30.130414Z","shell.execute_reply.started":"2024-04-29T10:00:23.555609Z","shell.execute_reply":"2024-04-29T10:00:30.129398Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/wide_resnet101_2-d733dc28.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet101_2-d733dc28.pth\n100%|██████████| 485M/485M [00:03<00:00, 151MB/s]  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Teacher network (PDN)","metadata":{}},{"cell_type":"code","source":"class TeacherNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=128, kernel_size=4, stride=1, padding=3),\n            nn.ReLU(),\n            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n            \n            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=1, padding=3),\n            nn.ReLU(),\n            nn.AvgPool2d(kernel_size=2, stride=2, padding=1),\n            \n            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=4, stride=1, padding=0),\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        return x\n\npdn = TeacherNetwork()\n\nif torch.cuda.device_count() > 1:\n    pdn = nn.DataParallel(pdn)\n\npdn = pdn.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:00:35.789493Z","iopub.execute_input":"2024-04-29T10:00:35.789859Z","iopub.status.idle":"2024-04-29T10:00:35.828678Z","shell.execute_reply.started":"2024-04-29T10:00:35.789829Z","shell.execute_reply":"2024-04-29T10:00:35.827653Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"mu_channel = []\nsig_channel = []\n\nfext.eval()\nfor i, (images, _) in enumerate(dataloader):\n\n    if i>15:\n        break\n\n    with torch.no_grad():\n        fext_out = fext(images)   \n\n    if i == 0:\n        sequence = fext_out\n\n    else:\n        sequence = torch.cat((sequence, fext_out), dim=0)\n\n\nsequence = sequence.mean(dim=0)\n\nfor tensr in sequence:\n    mu_channel.append(tensr.mean().item())\n    sig_channel.append(tensr.std().item())\n        \n        \nfext_normalize = transforms.Normalize(mean=mu_channel, std=sig_channel)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:00:37.541779Z","iopub.execute_input":"2024-04-29T10:00:37.542151Z","iopub.status.idle":"2024-04-29T10:01:02.551467Z","shell.execute_reply.started":"2024-04-29T10:00:37.542122Z","shell.execute_reply":"2024-04-29T10:01:02.550623Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:01:08.236546Z","iopub.execute_input":"2024-04-29T10:01:08.237477Z","iopub.status.idle":"2024-04-29T10:01:08.373990Z","shell.execute_reply.started":"2024-04-29T10:01:08.237438Z","shell.execute_reply":"2024-04-29T10:01:08.373017Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"39"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.MSELoss()\n\noptimizer = torch.optim.Adam(pdn.parameters(), lr=1e-4, weight_decay=1e-5)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:01:14.285495Z","iopub.execute_input":"2024-04-29T10:01:14.286563Z","iopub.status.idle":"2024-04-29T10:01:14.293051Z","shell.execute_reply.started":"2024-04-29T10:01:14.286518Z","shell.execute_reply":"2024-04-29T10:01:14.291152Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"random.seed(9)\n\nfext.eval()\npdn.train()\n\nfor epoch in range(5000):\n    \n    for bix in range(16):\n        \n        img_id = random.randint(0, len(fext_dataset)-1)\n        fext_image = fext_dataset[img_id][0]\n        pdn_image = pdn_dataset[img_id][0]\n#         image = grayscale_transform(image)\n        \n        fext_img = fext_image.unsqueeze(0).to(device)\n        pdn_img = pdn_image.unsqueeze(0).to(device)\n        \n        with torch.no_grad():\n            fext_out = fext(fext_img)\n            fext_out = fext_normalize(fext_out)\n            \n        pdn_out = pdn(pdn_img)\n        \n        loss = criterion(pdn_out, fext_out)\n        \n#         if bix==0:\n#             batch_loss = torch.tensor([loss.item()], requires_grad=True, device=device)\n#         else:\n#             batch_loss = torch.cat((batch_loss, torch.tensor([loss.item()], requires_grad=True, device=device)), dim=0)\n\n        if bix==0:\n            batch_loss = loss\n        else:\n            batch_loss = batch_loss + loss\n    \n\n    avg_loss = batch_loss/16\n\n    \n    if epoch==0 or (epoch+1)%200==0:\n        print(f\"Loss: {avg_loss}\")\n    \n    optimizer.zero_grad()\n    \n    avg_loss.backward()\n    \n    optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2024-04-29T10:01:25.725021Z","iopub.execute_input":"2024-04-29T10:01:25.725993Z","iopub.status.idle":"2024-04-29T12:39:04.900536Z","shell.execute_reply.started":"2024-04-29T10:01:25.725922Z","shell.execute_reply":"2024-04-29T12:39:04.899384Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Loss: 80.39542388916016\nLoss: 81.05866241455078\nLoss: 84.54275512695312\nLoss: 74.74446105957031\nLoss: 76.28498840332031\nLoss: 76.0407485961914\nLoss: 72.04757690429688\nLoss: 73.52398681640625\nLoss: 72.39143371582031\nLoss: 79.05269622802734\nLoss: 76.18132019042969\nLoss: 74.90377044677734\nLoss: 78.13765716552734\nLoss: 68.6776351928711\nLoss: 73.0262680053711\nLoss: 73.55596923828125\nLoss: 72.34915924072266\nLoss: 73.3984375\nLoss: 68.65929412841797\nLoss: 77.50553131103516\nLoss: 73.97562408447266\nLoss: 75.40345001220703\nLoss: 74.63668823242188\nLoss: 73.56914520263672\nLoss: 74.30719757080078\nLoss: 76.3548583984375\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(pdn.module.state_dict(), 'Teacher_model5000.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-29T12:39:19.865763Z","iopub.execute_input":"2024-04-29T12:39:19.866453Z","iopub.status.idle":"2024-04-29T12:39:19.890970Z","shell.execute_reply.started":"2024-04-29T12:39:19.866417Z","shell.execute_reply":"2024-04-29T12:39:19.889753Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}